{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1627942cd5834b43bba9fe4e9b3546ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_862e59ae303b4efeae962d8ab52d71ae",
              "IPY_MODEL_f265f2e3a2134d90a0b08fe1265420b8",
              "IPY_MODEL_5b26038f281f4285a62a1d783446694d"
            ],
            "layout": "IPY_MODEL_e2cd5d74cc4c4c34aebf690600e0b5d6"
          }
        },
        "862e59ae303b4efeae962d8ab52d71ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9898472b7be24de9ae1d687c7ba132be",
            "placeholder": "​",
            "style": "IPY_MODEL_92a7bc237c3447a5b2b41e1304b5bd2a",
            "value": "model.safetensors: 100%"
          }
        },
        "f265f2e3a2134d90a0b08fe1265420b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b84e8db40a44c49997f3809f9e2c51",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a2c22875d1442d5842844bf24788bce",
            "value": 440449768
          }
        },
        "5b26038f281f4285a62a1d783446694d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5afbce796b4dc3b6839279e431d640",
            "placeholder": "​",
            "style": "IPY_MODEL_a49e2b8058de42499b3256973d91ea70",
            "value": " 440M/440M [00:05&lt;00:00, 54.0MB/s]"
          }
        },
        "e2cd5d74cc4c4c34aebf690600e0b5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9898472b7be24de9ae1d687c7ba132be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a7bc237c3447a5b2b41e1304b5bd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b84e8db40a44c49997f3809f9e2c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a2c22875d1442d5842844bf24788bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a5afbce796b4dc3b6839279e431d640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a49e2b8058de42499b3256973d91ea70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "uqMWWNATGuDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install python3-tk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-AfSAVjM6vi",
        "outputId": "d96d1d2d-0900-413f-bf7a-ee4e02443cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-tk is already the newest version (3.10.8-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m6xzlRPjNcff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIxHpKJpO7RE",
        "outputId": "c75d1787-e45c-40e5-fd3d-1df401e64f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk83RY3GHF3V",
        "outputId": "a13b8d41-c3e2-45fa-8c1c-256cfd3bc9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18RQ8NPhSNcV",
        "outputId": "fd06d799-bada-47a4-d2a1-0b87300855b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering, Trainer, TrainingArguments\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"csv\", data_files={\"train\": \"400Data.csv\"})\n",
        "\n",
        "# Preprocess the data\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"Context\"], examples[\"Question\"], examples[\"Answer\"], truncation=True, padding=\"max_length\")\n",
        "\n",
        "dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Set up the model\n",
        "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Define a custom compute_metrics function\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": (predictions == labels).sum() / len(labels)}\n",
        "\n",
        "# Create the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train() '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492,
          "referenced_widgets": [
            "1627942cd5834b43bba9fe4e9b3546ba",
            "862e59ae303b4efeae962d8ab52d71ae",
            "f265f2e3a2134d90a0b08fe1265420b8",
            "5b26038f281f4285a62a1d783446694d",
            "e2cd5d74cc4c4c34aebf690600e0b5d6",
            "9898472b7be24de9ae1d687c7ba132be",
            "92a7bc237c3447a5b2b41e1304b5bd2a",
            "03b84e8db40a44c49997f3809f9e2c51",
            "7a2c22875d1442d5842844bf24788bce",
            "4a5afbce796b4dc3b6839279e431d640",
            "a49e2b8058de42499b3256973d91ea70"
          ]
        },
        "id": "QRaMg0IvQp5i",
        "outputId": "79e16839-6763-4026-ab61-04583e431813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1627942cd5834b43bba9fe4e9b3546ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Invalid key: 0. Please first select a split. For example: `my_dataset_dictionary['train'][0]`. Available splits: ['train']\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-75c36a253993>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrng_to_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     78\u001b[0m             ]\n\u001b[1;32m     79\u001b[0m             \u001b[0msuggested_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavailable_suggested_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mavailable_suggested_splits\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;34mf\"Invalid key: {k}. Please first select a split. For example: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;34mf\"`my_dataset_dictionary['{suggested_split}'][{k}]`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Invalid key: 0. Please first select a split. For example: `my_dataset_dictionary['train'][0]`. Available splits: ['train']\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtHhmNTKRkL7",
        "outputId": "ecc9814b-532a-4afd-cd2c-8085c1743ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/280.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/280.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Load the dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"csv\", data_files={\"train\": \"400Data.csv\"})\n",
        "\n",
        "# Preprocess the data\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"Context\"], examples[\"Question\"], examples[\"Answer\"], truncation=True, padding=\"max_length\")\n",
        "\n",
        "dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Set up training arguments\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Set up the model\n",
        "from transformers import BertForQuestionAnswering\n",
        "\n",
        "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Define a custom compute_metrics function\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": (predictions == labels).sum() / len(labels)}\n",
        "\n",
        "# Create the Trainer\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zBnUSW0ST9v",
        "outputId": "712f10da-2fe5-4419-b960-b971a5fcc9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2RkRDQNPqJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the Data\n",
        "df = pd.read_csv(\"400Data.csv\")  # Replace \"your_data.csv\" with the path to your CSV file\n",
        "df.dropna(subset=[\"Question\"], inplace=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02frDPZPYQuO",
        "outputId": "925f006e-97c0-4fa4-9579-1fc4f6c1c4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Context            0\n",
              "Question           0\n",
              "Answer             0\n",
              "Hallucination      0\n",
              "Prediction       401\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess the Text Data\n",
        "texts = df[['Context', 'Question', 'Answer']].apply(lambda x: ' '.join(x), axis=1)  # Concatenate three text columns into one\n",
        "labels = df['Hallucination'].values\n",
        "\n",
        "# Step 3: Split the Data into Train and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Vectorize the Text Data\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter as needed\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 5: Train the Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Step 6: Make Predictions\n",
        "y_pred = clf.predict(X_test_vectorized)\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJA2G1hSaaMd",
        "outputId": "b64ed402-bfbf-4e72-c934-ab782b010587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8641975308641975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Step 1: Load the Data\n",
        "df = pd.read_csv(\"400Data.csv\")  # Replace \"your_data.csv\" with the path to your CSV file\n",
        "df.dropna(subset=[\"Question\"], inplace=True)\n",
        "df.isnull().sum()\n",
        "\n",
        "# Step 2: Preprocess the Text Data\n",
        "texts = df[['Context', 'Question', 'Answer']].apply(lambda x: ' '.join(x), axis=1)  # Concatenate three text columns into one\n",
        "labels = df['Hallucination'].values\n",
        "\n",
        "# Step 3: Split the Data into Train and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Vectorize the Text Data\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter as needed\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 5: Train the Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42, criterion='entropy')  # Change the criterion to 'entropy'\n",
        "clf.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Step 6: Make Predictions\n",
        "y_pred = clf.predict(X_test_vectorized)\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\",accuracy)\n"
      ],
      "metadata": {
        "id": "SgAU9sgucZob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the Data\n",
        "df = pd.read_csv(\"400Data.csv\")  # Replace \"your_data.csv\" with the path to your CSV file\n",
        "df.dropna(subset=[\"Question\"], inplace=True)\n",
        "df.isnull().sum()\n",
        "\n",
        "# Step 2: Preprocess the Text Data\n",
        "texts = df[['Context', 'Question', 'Answer']].apply(lambda x: ' '.join(map(str, x)), axis=1)  # Handle non-string values\n",
        "labels = df['Hallucination'].values\n",
        "\n",
        "# Step 3: Split the Data into Train and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Vectorize the Text Data\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter as needed\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 5: Train the Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Step 6: Make Predictions\n",
        "y_pred = clf.predict(X_test_vectorized)\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Step 8: Load the new data from a CSV file\n",
        "new_data = pd.read_csv(\"result.csv\")  # Replace \"new_data.csv\" with the path to your new data file\n",
        "\n",
        "# Step 9: Preprocess the new text data\n",
        "new_texts = new_data[['Context', 'Question', 'Answer']].apply(lambda x: ' '.join(map(str, x)), axis=1)  # Handle non-string values\n",
        "\n",
        "# Step 10: Vectorize the new text data\n",
        "new_texts_vectorized = vectorizer.transform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0QVkVl_cePi",
        "outputId": "e4006d03-7054-4949-e385-6f477ec3814e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8641975308641975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=clf.predict(vectorizer.transform(X_train))\n",
        "accuracy_score(y_train,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C74mTzqkgvn5",
        "outputId": "7a9e7074-d21c-4d80-a911-36345973ad06"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: remove overfitting from above code\n",
        "\n",
        "# Step 1: Load the Data\n",
        "df = pd.read_csv(\"400Data.csv\")  # Replace \"your_data.csv\" with the path to your CSV file\n",
        "df.dropna(subset=[\"Question\"], inplace=True)\n",
        "df.isnull().sum()\n",
        "\n",
        "# Step 2: Preprocess the Text Data\n",
        "texts = df[['Context', 'Question', 'Answer']].apply(lambda x: ' '.join(map(str, x)), axis=1)  # Handle non-string values\n",
        "labels = df['Hallucination'].values\n",
        "\n",
        "# Step 3: Split the Data into Train and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Vectorize the Text Data\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # You can adjust the max_features parameter as needed\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 5: Train the Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Step 6: Make Predictions\n",
        "y_pred = clf.predict(X_test_vectorized)\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Step 8: Load the new data from a CSV file\n",
        "new_data = pd.read_csv(\"result.csv\")  # Replace \"new_data.csv\" with the path to your new data file\n",
        "\n",
        "# Step 9: Preprocess the new text data\n",
        "new_texts = new_data[['Context', 'Question', 'Answer']].apply(lambda x: ' '.join(map(str, x)), axis=1)  # Handle non-string values\n",
        "\n",
        "# Step 10: Vectorize the new text data\n",
        "new_texts_vectorized = vectorizer.transform\n",
        "y=clf.predict(vectorizer.transform(X_train))\n",
        "accuracy_score(y_train,y)\n",
        "\n",
        "# Step 11: Reduce Overfitting\n",
        "# Option 1: Use Cross-Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_train_vectorized, y_train, cv=5)\n",
        "print(\"Cross-validation accuracy:\", scores.mean())\n",
        "\n",
        "# Option 2: Use GridSearchCV to find the best parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'n_estimators': [50, 100, 150], 'max_depth': [5, 10, 15]}\n",
        "clf_grid = GridSearchCV(clf, parameters, cv=5)\n",
        "clf_grid.fit(X_train_vectorized, y_train)\n",
        "print(\"Best parameters:\", clf_grid.best_params_)\n",
        "\n",
        "# Option 3: Use Regularization\n",
        "clf_reg = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
        "clf_reg.fit(X_train_vectorized, y_train)\n",
        "y_pred_reg = clf_reg.predict(X_test_vectorized)\n",
        "accuracy_reg = accuracy_score(y_test, y_pred_reg)\n",
        "print(\"Accuracy with regularization:\", accuracy_reg)\n",
        "\n",
        "# Step 12: Choose the best model based on the evaluation results and use it to make predictions on the new data\n",
        "best_model = clf  # Choose the best model based on your evaluation criteria\n",
        "new_predictions = best_model.predict(vectorizer.transform(new_texts))\n",
        "\n",
        "# Step 13: Analyze the results and draw conclusions\n",
        "# ...\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxxq5AhFhgBd",
        "outputId": "ce38e634-5ad0-4d9f-9e49-d761928f5367"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8641975308641975\n",
            "Cross-validation accuracy: 0.75625\n",
            "Best parameters: {'max_depth': 10, 'n_estimators': 150}\n",
            "Accuracy with regularization: 0.7654320987654321\n",
            "Accuracy: 0.8641975308641975\n",
            "Precision: 0.84375\n",
            "Recall: 0.9818181818181818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 14: Visualize the results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a bar chart to visualize the distribution of predicted labels\n",
        "labels, counts = np.unique(new_predictions, return_counts=True)\n",
        "plt.bar(labels, counts)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Predicted Labels\")\n",
        "plt.show()\n",
        "\n",
        "# Step 15: Write the results to a file\n",
        "with open(\"predictions.csv\", \"w\") as f:\n",
        "    f.write(\"Context,Question,Answer,Prediction\\n\")\n",
        "    for i in range(len(new_texts)):\n",
        "        f.write(f\"{new_data['Context'][i]},{new_data['Question'][i]},{new_data['Answer'][i]},{new_predictions[i]}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tl8fJS3nlaCS",
        "outputId": "7f4dd8d0-1fd4-4509-ac5a-7531faa78945"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=clf.predict(vectorizer.transform(X_train))\n",
        "accuracy_score(y_train,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDWUcXn0h-D6",
        "outputId": "3fe9bd1b-2faf-47f4-8684-0755ced7a895"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the Data\n",
        "df = pd.read_csv(\"400Data.csv\")\n",
        "df.dropna(subset=[\"Question\"], inplace=True)\n",
        "\n",
        "# Step 2: Preprocess the Text Data\n",
        "texts = df[['Context', 'Question', 'Answer']].apply(lambda x: ' '.join(map(str, x)), axis=1)\n",
        "labels = df['Hallucination'].values\n",
        "\n",
        "# Step 3: Split the Data into Train and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Vectorize the Text Data\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Step 5: Train the Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Step 6: Make Predictions on New Data\n",
        "new_data = pd.read_csv(\"400Data.csv\")\n",
        "new_texts = new_data[['Context', 'Question', 'Answer']].apply(lambda x: ' '.join(map(str, x)), axis=1)\n",
        "new_texts_vectorized = vectorizer.transform(new_texts)\n",
        "new_predictions = clf.predict(new_texts_vectorized)\n",
        "\n",
        "# Step 7: Save the Predictions to the Result File\n",
        "result_df = pd.read_csv(\"result.csv\")\n",
        "result_df[\"Prediction\"] = new_predictions\n",
        "result_df.to_csv(\"result.csv\", index=False)"
      ],
      "metadata": {
        "id": "iIH8tUfCl6gO"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: check the values of  result.csv in column Hallucination and Prediction how many are matching\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the result.csv file\n",
        "result_df = pd.read_csv(\"result.csv\")\n",
        "\n",
        "# Count the number of matching values between Hallucination and Prediction columns\n",
        "matching_values = (result_df[\"Hallucination\"] == result_df[\"Prediction\"]).sum()\n",
        "\n",
        "# Print the number of matching values\n",
        "print(f\"Number of matching values: {matching_values}\")\n"
      ],
      "metadata": {
        "id": "MW1qwDSBofV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}